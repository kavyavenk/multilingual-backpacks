{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "707d3ec9",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e704e3f",
   "metadata": {},
   "source": [
    "## ⚠️ Training Result: OOM Error\n",
    "\n",
    "**Target**: ~500K parameter model  \n",
    "**Actual**: ~60M parameter model  \n",
    "**Result**: Out of Memory on T4 GPU (even with batch_size=1)\n",
    "\n",
    "### Why?\n",
    "Using XLM-RoBERTa's pre-trained tokenizer with 250K vocabulary:\n",
    "- **Sense embeddings**: 250K tokens × 4 senses × 48 dims = **48M params**\n",
    "- Transformer layers: ~12M params\n",
    "- **Total**: **60M parameters** (120x larger than target!)\n",
    "\n",
    "### The Problem\n",
    "- T4 has 15GB memory\n",
    "- 60M model needs ~11GB just for forward pass\n",
    "- Backward pass (gradients) needs another ~11GB\n",
    "- Total needed: **~22GB** → OOM error!\n",
    "\n",
    "### Solution for True 500K Model\n",
    "To get actual 500K params, you need:\n",
    "1. **Custom vocabulary**: ~2000 tokens (not 250K)\n",
    "   - This gives: 2K × 4 × 48 = 384K embedding params\n",
    "   - Plus layers ≈ **500K total** ✓\n",
    "   \n",
    "2. **Or**: Use smaller embedding dim (n_embd=24, n_senses=2)\n",
    "   - 250K × 2 × 24 = 12M (still too large)\n",
    "\n",
    "### Recommendation\n",
    "**For your project**, document this finding:\n",
    "- XLM-RoBERTa tokenizer creates model that's 120x target size\n",
    "- Need custom small vocabulary for truly tiny models\n",
    "- Alternative: Test with standard transformer baseline (no sense vectors)\n",
    "\n",
    "**Next steps**: Train transformer baseline without Backpack architecture to demonstrate cross-lingual learning with smaller model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c102d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 25 03:12:04 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   49C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370e5834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'multilingual-backpacks'...\n",
      "remote: Enumerating objects: 271, done.\u001b[K\n",
      "remote: Counting objects: 100% (56/56), done.\u001b[K\n",
      "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
      "remote: Total 271 (delta 17), reused 49 (delta 14), pack-reused 215 (from 1)\u001b[K\n",
      "Receiving objects: 100% (271/271), 149.16 KiB | 8.77 MiB/s, done.\n",
      "Resolving deltas: 100% (132/132), done.\n",
      "/content/multilingual-backpacks/multilingual-backpacks\n",
      "remote: Enumerating objects: 271, done.\u001b[K\n",
      "remote: Counting objects: 100% (56/56), done.\u001b[K\n",
      "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
      "remote: Total 271 (delta 17), reused 49 (delta 14), pack-reused 215 (from 1)\u001b[K\n",
      "Receiving objects: 100% (271/271), 149.16 KiB | 8.77 MiB/s, done.\n",
      "Resolving deltas: 100% (132/132), done.\n",
      "/content/multilingual-backpacks/multilingual-backpacks\n"
     ]
    }
   ],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/kavyavenk/multilingual-backpacks.git\n",
    "%cd multilingual-backpacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fc6e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q transformers datasets scipy tqdm numpy torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d76d13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.9.0+cu126\n",
      "CUDA available: True\n",
      "GPU: Tesla T4\n",
      "Memory: 15.83 GB\n"
     ]
    }
   ],
   "source": [
    "# Verify imports\n",
    "import torch\n",
    "import numpy as np\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d159d9",
   "metadata": {},
   "source": [
    "## 2. Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbf795b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Europarl dataset for en-fr...\n",
      "README.md: 76.3kB [00:00, 129MB/s]\n",
      "README.md: 76.3kB [00:00, 129MB/s]\n",
      "en-fr/train-00000-of-00002.parquet: 100% 193M/193M [00:03<00:00, 52.2MB/s]   \n",
      "en-fr/train-00000-of-00002.parquet: 100% 193M/193M [00:03<00:00, 52.2MB/s]\n",
      "en-fr/train-00001-of-00002.parquet: 100% 186M/186M [00:01<00:00, 130MB/s]  \n",
      "en-fr/train-00001-of-00002.parquet: 100% 186M/186M [00:01<00:00, 130MB/s]  \n",
      "Generating train split: 100% 2051014/2051014 [00:06<00:00, 320563.38 examples/s]\n",
      "Loaded Europarl en-fr from HuggingFace\n",
      "Using subset of 10000 sentences (out of 2051014 total)\n",
      "Loading tokenizer: xlm-roberta-base\n",
      "Generating train split: 100% 2051014/2051014 [00:06<00:00, 320563.38 examples/s]\n",
      "Loaded Europarl en-fr from HuggingFace\n",
      "Using subset of 10000 sentences (out of 2051014 total)\n",
      "Loading tokenizer: xlm-roberta-base\n",
      "tokenizer_config.json: 100% 25.0/25.0 [00:00<00:00, 175kB/s]\n",
      "config.json: 100% 615/615 [00:00<00:00, 6.11MB/s]\n",
      "tokenizer_config.json: 100% 25.0/25.0 [00:00<00:00, 175kB/s]\n",
      "config.json: 100% 615/615 [00:00<00:00, 6.11MB/s]\n",
      "sentencepiece.bpe.model: 100% 5.07M/5.07M [00:00<00:00, 13.6MB/s]\n",
      "sentencepiece.bpe.model: 100% 5.07M/5.07M [00:00<00:00, 13.6MB/s]\n",
      "tokenizer.json: 100% 9.10M/9.10M [00:00<00:00, 32.5MB/s]\n",
      "tokenizer.json: 100% 9.10M/9.10M [00:00<00:00, 32.5MB/s]\n",
      "Processing sentences: 100% 10000/10000 [00:00<00:00, 42808.41it/s]\n",
      "Total combined texts: 20000\n",
      "Tokenizing texts (this may take a few minutes)...\n",
      "Tokenizing 18000 training texts...\n",
      "Processing sentences: 100% 10000/10000 [00:00<00:00, 42808.41it/s]\n",
      "Total combined texts: 20000\n",
      "Tokenizing texts (this may take a few minutes)...\n",
      "Tokenizing 18000 training texts...\n",
      "Train batches: 100% 18/18 [00:05<00:00,  3.55it/s]\n",
      "Tokenizing 2000 validation texts...\n",
      "Train batches: 100% 18/18 [00:05<00:00,  3.55it/s]\n",
      "Tokenizing 2000 validation texts...\n",
      "Val batches: 100% 2/2 [00:00<00:00,  4.60it/s]\n",
      "Saved train data to /content/multilingual-backpacks/multilingual-backpacks/data/europarl/train.bin\n",
      "Saved val data to /content/multilingual-backpacks/multilingual-backpacks/data/europarl/val.bin\n",
      "Saved metadata to /content/multilingual-backpacks/multilingual-backpacks/data/europarl/meta.pkl\n",
      "\n",
      "Vocabulary size: 250002\n",
      "Data preparation complete!\n",
      "Val batches: 100% 2/2 [00:00<00:00,  4.60it/s]\n",
      "Saved train data to /content/multilingual-backpacks/multilingual-backpacks/data/europarl/train.bin\n",
      "Saved val data to /content/multilingual-backpacks/multilingual-backpacks/data/europarl/val.bin\n",
      "Saved metadata to /content/multilingual-backpacks/multilingual-backpacks/data/europarl/meta.pkl\n",
      "\n",
      "Vocabulary size: 250002\n",
      "Data preparation complete!\n"
     ]
    }
   ],
   "source": [
    "# Prepare Europarl dataset (10k samples for quick training)\n",
    "!python data/europarl/prepare.py --language_pair en-fr --max_samples 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f9678e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom tiny vocabulary (2K tokens) from Europarl data\n",
    "# This will make the model truly ~500K params instead of 60M\n",
    "\n",
    "!python -c \"\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "\n",
    "print('Creating tiny custom vocabulary...')\n",
    "\n",
    "# Load small subset\n",
    "dataset = load_dataset('europarl_bilingual', 'en-fr', split='train[:1000]')\n",
    "\n",
    "# Collect all words\n",
    "all_words = []\n",
    "for item in dataset:\n",
    "    # Simple word tokenization (split on whitespace and punctuation)\n",
    "    text = item['translation']['en'] + ' ' + item['translation']['fr']\n",
    "    words = re.findall(r'\\w+|[^\\w\\s]', text.lower())\n",
    "    all_words.extend(words)\n",
    "\n",
    "# Get most common 2000 words\n",
    "word_counts = Counter(all_words)\n",
    "vocab = ['<pad>', '<unk>', '<s>', '</s>'] + [w for w, _ in word_counts.most_common(1996)]\n",
    "\n",
    "print(f'Created vocabulary with {len(vocab)} tokens')\n",
    "\n",
    "# Save vocab\n",
    "vocab_dict = {w: i for i, w in enumerate(vocab)}\n",
    "with open('data/europarl/tiny_vocab.pkl', 'wb') as f:\n",
    "    pickle.dump({'vocab': vocab_dict, 'vocab_size': len(vocab)}, f)\n",
    "\n",
    "print('✓ Tiny vocabulary saved to data/europarl/tiny_vocab.pkl')\n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968d0fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ data/europarl/train.bin (5.88 MB)\n",
      "✓ data/europarl/val.bin (0.66 MB)\n",
      "✓ data/europarl/meta.pkl (0.00 MB)\n",
      "\n",
      "Vocab size: 250,002\n",
      "Languages: ['en', 'fr']\n"
     ]
    }
   ],
   "source": [
    "# Verify data files\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "data_files = ['data/europarl/train.bin', 'data/europarl/val.bin', 'data/europarl/meta.pkl']\n",
    "for f in data_files:\n",
    "    if os.path.exists(f):\n",
    "        size = os.path.getsize(f) / 1e6\n",
    "        print(f\"✓ {f} ({size:.2f} MB)\")\n",
    "    else:\n",
    "        print(f\"✗ {f} not found\")\n",
    "\n",
    "# Load metadata\n",
    "with open('data/europarl/meta.pkl', 'rb') as f:\n",
    "    meta = pickle.load(f)\n",
    "print(f\"\\nVocab size: {meta['vocab_size']:,}\")\n",
    "print(f\"Languages: {meta['languages']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de6ed42",
   "metadata": {},
   "source": [
    "## 3. Configure Model for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f5483e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Config updated for GPU training\n"
     ]
    }
   ],
   "source": [
    "# Update config for GPU training with MINIMAL memory settings\n",
    "# Model is ~60M params - need batch_size=1 for T4\n",
    "\n",
    "# Read current config\n",
    "with open('config/train_europarl_tiny.py', 'r') as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Update config with minimal memory settings\n",
    "import re\n",
    "\n",
    "# Replace device and dtype\n",
    "content = re.sub(r\"device='.*'\", \"device='cuda'\", content)\n",
    "content = re.sub(r\"dtype='.*'\", \"dtype='float16'\", content)\n",
    "\n",
    "# MINIMAL batch size for 60M model on T4\n",
    "content = re.sub(r\"batch_size=\\d+\", \"batch_size=1\", content)\n",
    "\n",
    "# Fewer iterations for testing\n",
    "content = re.sub(r\"max_iters=\\d+\", \"max_iters=500\", content)\n",
    "\n",
    "# Very small block size to save memory\n",
    "content = re.sub(r\"block_size=\\d+\", \"block_size=32\", content)\n",
    "\n",
    "# Reduce eval iterations\n",
    "content = re.sub(r\"eval_iters=\\d+\", \"eval_iters=10\", content)\n",
    "\n",
    "# Write updated config\n",
    "with open('config/train_europarl_tiny.py', 'w') as f:\n",
    "    f.write(content)\n",
    "\n",
    "print(\"✓ Config updated for minimal GPU memory usage\")\n",
    "print(\"  - Batch size: 1 (minimal for 60M model)\")\n",
    "print(\"  - Block size: 32 (very short context)\")\n",
    "print(\"  - Max iterations: 500 (quick test)\")\n",
    "print(\"  - Eval iters: 10\")\n",
    "print(\"  - Device: cuda, dtype: float16\")\n",
    "print(\"\\n⚠️  Model is ~60M params - this is a memory test run!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b8bfa6",
   "metadata": {},
   "source": [
    "## 4. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806f6f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear GPU memory and set memory optimization\n",
    "import torch\n",
    "import gc\n",
    "import os\n",
    "\n",
    "# Set PyTorch memory optimization\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    # Check available memory\n",
    "    mem_total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    mem_reserved = torch.cuda.memory_reserved(0) / 1e9\n",
    "    mem_allocated = torch.cuda.memory_allocated(0) / 1e9\n",
    "    mem_free = mem_total - mem_allocated\n",
    "    \n",
    "    print(f\"GPU Memory Status:\")\n",
    "    print(f\"  Total: {mem_total:.2f} GB\")\n",
    "    print(f\"  Allocated: {mem_allocated:.2f} GB\")\n",
    "    print(f\"  Reserved: {mem_reserved:.2f} GB\")\n",
    "    print(f\"  Free: {mem_free:.2f} GB\")\n",
    "    print(f\"\\n✓ GPU memory cleared and optimized for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c313b7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loading train.bin\n",
      "Loading val.bin\n",
      "Loading meta.pkl\n",
      "Initializing model...\n",
      "Backpack from scratch\n",
      "Number of parameters: 60.06M\n",
      "Backpack initialized (scratch)\n",
      "Number of parameters: 60.06M\n",
      "Backpack initialized (scratch)\n",
      "num decayed parameter tensors: 13, with 60,064,416 parameters\n",
      "num non-decayed parameter tensors: 7, with 292 parameters\n",
      "Starting training...\n",
      "num decayed parameter tensors: 13, with 60,064,416 parameters\n",
      "num non-decayed parameter tensors: 7, with 292 parameters\n",
      "Starting training...\n",
      "X bounds:  0 242661\n",
      "Y bounds:  0 242661\n",
      "X bounds:  0 242661\n",
      "Y bounds:  0 242661\n",
      "X bounds:  0 241925\n",
      "Y bounds:  0 241925\n",
      "X bounds:  0 242893\n",
      "Y bounds:  0 242893\n",
      "X bounds:  0 242661\n",
      "Y bounds:  0 242661\n",
      "X bounds:  0 241925\n",
      "Y bounds:  0 241925\n",
      "X bounds:  0 242893\n",
      "Y bounds:  0 242893\n",
      "X bounds:  0 242661\n",
      "Y bounds:  0 242661\n",
      "X bounds:  0 242435\n",
      "Y bounds:  0 242435\n",
      "X bounds:  0 243317\n",
      "Y bounds:  0 243317\n",
      "X bounds:  0 242435\n",
      "Y bounds:  0 242435\n",
      "X bounds:  0 243317\n",
      "Y bounds:  0 243317\n",
      "X bounds:  0 242799\n",
      "Y bounds:  0 242799\n",
      "X bounds:  0 242661\n",
      "Y bounds:  0 242661\n",
      "X bounds:  0 242799\n",
      "Y bounds:  0 242799\n",
      "X bounds:  0 242661\n",
      "Y bounds:  0 242661\n",
      "X bounds:  0 240131\n",
      "Y bounds:  0 240131\n",
      "X bounds:  0 239483\n",
      "Y bounds:  0 239483\n",
      "X bounds:  0 242799\n",
      "Y bounds:  0 242799\n",
      "X bounds:  0 240131\n",
      "Y bounds:  0 240131\n",
      "X bounds:  0 239483\n",
      "Y bounds:  0 239483\n",
      "X bounds:  0 242799\n",
      "Y bounds:  0 242799\n",
      "X bounds:  0 242799\n",
      "Y bounds:  0 242799\n",
      "X bounds:  0 240804\n",
      "Y bounds:  0 240804\n",
      "X bounds:  0 242796\n",
      "Y bounds:  0 242796\n",
      "X bounds:  0 242799\n",
      "Y bounds:  0 242799\n",
      "X bounds:  0 240804\n",
      "Y bounds:  0 240804\n",
      "X bounds:  0 242796\n",
      "Y bounds:  0 242796\n",
      "X bounds:  0 242564\n",
      "Y bounds:  0 242564\n",
      "X bounds:  0 242964\n",
      "Y bounds:  0 242964\n",
      "X bounds:  0 240625\n",
      "Y bounds:  0 240625\n",
      "X bounds:  0 242564\n",
      "Y bounds:  0 242564\n",
      "X bounds:  0 242964\n",
      "Y bounds:  0 242964\n",
      "X bounds:  0 240625\n",
      "Y bounds:  0 240625\n",
      "X bounds:  0 242435\n",
      "Y bounds:  0 242435\n",
      "X bounds:  0 242983\n",
      "Y bounds:  0 242983\n",
      "X bounds:  0 242799\n",
      "Y bounds:  0 242799\n",
      "X bounds:  0 242435\n",
      "Y bounds:  0 242435\n",
      "X bounds:  0 242983\n",
      "Y bounds:  0 242983\n",
      "X bounds:  0 242799\n",
      "Y bounds:  0 242799\n",
      "X bounds:  0 241439\n",
      "Y bounds:  0 241439\n",
      "X bounds:  0 242446\n",
      "Y bounds:  0 242446\n",
      "X bounds:  0 241439\n",
      "Y bounds:  0 241439\n",
      "X bounds:  0 242446\n",
      "Y bounds:  0 242446\n",
      "X bounds:  0 240906\n",
      "Y bounds:  0 240906\n",
      "X bounds:  0 242661\n",
      "Y bounds:  0 242661\n",
      "X bounds:  0 242980\n",
      "Y bounds:  0 242980\n",
      "X bounds:  0 240906\n",
      "Y bounds:  0 240906\n",
      "X bounds:  0 242661\n",
      "Y bounds:  0 242661\n",
      "X bounds:  0 242980\n",
      "Y bounds:  0 242980\n",
      "X bounds:  0 242639\n",
      "Y bounds:  0 242639\n",
      "X bounds:  0 242799\n",
      "Y bounds:  0 242799\n",
      "X bounds:  0 242980\n",
      "Y bounds:  0 242980\n",
      "X bounds:  0 242639\n",
      "Y bounds:  0 242639\n",
      "X bounds:  0 242799\n",
      "Y bounds:  0 242799\n",
      "X bounds:  0 242980\n",
      "Y bounds:  0 242980\n",
      "X bounds:  0 243317\n",
      "Y bounds:  0 243317\n",
      "X bounds:  0 242627\n",
      "Y bounds:  0 242627\n",
      "X bounds:  0 243317\n",
      "Y bounds:  0 243317\n",
      "X bounds:  0 242627\n",
      "Y bounds:  0 242627\n",
      "X bounds:  0 243317\n",
      "Y bounds:  0 243317\n",
      "X bounds:  0 242627\n",
      "Y bounds:  0 242627\n",
      "X bounds:  0 236131\n",
      "Y bounds:  0 236131\n",
      "X bounds:  0 243317\n",
      "Y bounds:  0 243317\n",
      "X bounds:  0 242627\n",
      "Y bounds:  0 242627\n",
      "X bounds:  0 236131\n",
      "Y bounds:  0 236131\n",
      "X bounds:  0 242670\n",
      "Y bounds:  0 242670\n",
      "X bounds:  0 240625\n",
      "Y bounds:  0 240625\n",
      "X bounds:  0 238236\n",
      "Y bounds:  0 238236\n",
      "X bounds:  0 242670\n",
      "Y bounds:  0 242670\n",
      "X bounds:  0 240625\n",
      "Y bounds:  0 240625\n",
      "X bounds:  0 238236\n",
      "Y bounds:  0 238236\n",
      "X bounds:  0 242435\n",
      "Y bounds:  0 242435\n",
      "X bounds:  0 241925\n",
      "Y bounds:  0 241925\n",
      "X bounds:  0 242435\n",
      "Y bounds:  0 242435\n",
      "X bounds:  0 241925\n",
      "Y bounds:  0 241925\n",
      "X bounds:  0 242661\n",
      "Y bounds:  0 242661\n",
      "X bounds:  0 242799\n",
      "Y bounds:  0 242799\n",
      "X bounds:  0 240098\n",
      "Y bounds:  0 240098\n",
      "X bounds:  0 242661\n",
      "Y bounds:  0 242661\n",
      "X bounds:  0 242799\n",
      "Y bounds:  0 242799\n",
      "X bounds:  0 240098\n",
      "Y bounds:  0 240098\n",
      "X bounds:  0 242799\n",
      "Y bounds:  0 242799\n",
      "X bounds:  0 242627\n",
      "Y bounds:  0 242627\n",
      "X bounds:  0 243317\n",
      "Y bounds:  0 243317\n",
      "X bounds:  0 242799\n",
      "Y bounds:  0 242799\n",
      "X bounds:  0 242627\n",
      "Y bounds:  0 242627\n",
      "X bounds:  0 243317\n",
      "Y bounds:  0 243317\n",
      "X bounds:  0 242435\n",
      "Y bounds:  0 242435\n",
      "X bounds:  0 243317\n",
      "Y bounds:  0 243317\n",
      "X bounds:  0 242435\n",
      "Y bounds:  0 242435\n",
      "X bounds:  0 243317\n",
      "Y bounds:  0 243317\n",
      "X bounds:  0 242661\n",
      "Y bounds:  0 242661\n",
      "X bounds:  0 235923\n",
      "Y bounds:  0 235923\n",
      "X bounds:  0 242810\n",
      "Y bounds:  0 242810\n",
      "X bounds:  0 242661\n",
      "Y bounds:  0 242661\n",
      "X bounds:  0 235923\n",
      "Y bounds:  0 235923\n",
      "X bounds:  0 242810\n",
      "Y bounds:  0 242810\n",
      "X bounds:  0 242799\n",
      "Y bounds:  0 242799\n",
      "X bounds:  0 242661\n",
      "Y bounds:  0 242661\n",
      "X bounds:  0 234694\n",
      "Y bounds:  0 234694\n",
      "X bounds:  0 242799\n",
      "Y bounds:  0 242799\n",
      "X bounds:  0 242661\n",
      "Y bounds:  0 242661\n",
      "X bounds:  0 234694\n",
      "Y bounds:  0 234694\n",
      "X bounds:  0 242799\n",
      "Y bounds:  0 242799\n",
      "X bounds:  0 243317\n",
      "Y bounds:  0 243317\n",
      "X bounds:  0 242799\n",
      "Y bounds:  0 242799\n",
      "X bounds:  0 243317\n",
      "Y bounds:  0 243317\n",
      "X bounds:  0 242661\n",
      "Y bounds:  0 242661\n",
      "X bounds:  0 242980\n",
      "Y bounds:  0 242980\n",
      "X bounds:  0 242799\n",
      "Y bounds:  0 242799\n",
      "X bounds:  0 242661\n",
      "Y bounds:  0 242661\n",
      "X bounds:  0 242980\n",
      "Y bounds:  0 242980\n",
      "X bounds:  0 242799\n",
      "Y bounds:  0 242799\n",
      "X bounds:  0 242799\n",
      "Y bounds:  0 242799\n",
      "X bounds:  0 243317\n",
      "Y bounds:  0 243317\n",
      "X bounds:  0 242799\n",
      "Y bounds:  0 242799\n",
      "X bounds:  0 243317\n",
      "Y bounds:  0 243317\n",
      "X bounds:  0 241925\n",
      "Y bounds:  0 241925\n",
      "X bounds:  0 242661\n",
      "Y bounds:  0 242661\n",
      "X bounds:  0 241925\n",
      "Y bounds:  0 241925\n",
      "X bounds:  0 242661\n",
      "Y bounds:  0 242661\n",
      "X bounds:  0 234532\n",
      "Y bounds:  0 234532\n",
      "X bounds:  0 240239\n",
      "Y bounds:  0 240239\n",
      "X bounds:  0 234532\n",
      "Y bounds:  0 234532\n",
      "X bounds:  0 240239\n",
      "Y bounds:  0 240239\n",
      "X bounds:  0 240776\n",
      "Y bounds:  0 240776\n",
      "X bounds:  0 241724\n",
      "Y bounds:  0 241724\n",
      "X bounds:  0 240776\n",
      "Y bounds:  0 240776\n",
      "X bounds:  0 240776\n",
      "Y bounds:  0 240776\n",
      "X bounds:  0 241724\n",
      "Y bounds:  0 241724\n",
      "X bounds:  0 240776\n",
      "Y bounds:  0 240776\n",
      "X bounds:  0 243317\n",
      "Y bounds:  0 243317\n",
      "X bounds:  0 242661\n",
      "Y bounds:  0 242661\n",
      "X bounds:  0 243317\n",
      "Y bounds:  0 243317\n",
      "X bounds:  0 234694\n",
      "Y bounds:  0 234694\n",
      "X bounds:  0 243317\n",
      "Y bounds:  0 243317\n",
      "X bounds:  0 242661\n",
      "Y bounds:  0 242661\n",
      "X bounds:  0 243317\n",
      "Y bounds:  0 243317\n",
      "X bounds:  0 234694\n",
      "Y bounds:  0 234694\n",
      "X bounds:  0 242799\n",
      "Y bounds:  0 242799\n",
      "X bounds:  0 241846\n",
      "Y bounds:  0 241846\n",
      "X bounds:  0 240906\n",
      "Y bounds:  0 240906\n",
      "X bounds:  0 242799\n",
      "Y bounds:  0 242799\n",
      "X bounds:  0 241846\n",
      "Y bounds:  0 241846\n",
      "X bounds:  0 240906\n",
      "Y bounds:  0 240906\n",
      "X bounds:  0 237854\n",
      "Y bounds:  0 237854\n",
      "X bounds:  0 241925\n",
      "Y bounds:  0 241925\n",
      "X bounds:  0 237854\n",
      "Y bounds:  0 237854\n",
      "X bounds:  0 241925\n",
      "Y bounds:  0 241925\n",
      "X bounds:  0 242661\n",
      "Y bounds:  0 242661\n",
      "X bounds:  0 242980\n",
      "Y bounds:  0 242980\n",
      "X bounds:  0 242980\n",
      "Y bounds:  0 242980\n",
      "X bounds:  0 242661\n",
      "Y bounds:  0 242661\n",
      "X bounds:  0 242980\n",
      "Y bounds:  0 242980\n",
      "X bounds:  0 242980\n",
      "Y bounds:  0 242980\n",
      "X bounds:  0 242435\n",
      "Y bounds:  0 242435\n",
      "X bounds:  0 242799\n",
      "Y bounds:  0 242799\n",
      "X bounds:  0 240776\n",
      "Y bounds:  0 240776\n",
      "X bounds:  0 242435\n",
      "Y bounds:  0 242435\n",
      "X bounds:  0 242799\n",
      "Y bounds:  0 242799\n",
      "X bounds:  0 240776\n",
      "Y bounds:  0 240776\n",
      "X bounds:  0 242661\n",
      "Y bounds:  0 242661\n",
      "X bounds:  0 242796\n",
      "Y bounds:  0 242796\n",
      "X bounds:  0 233131\n",
      "Y bounds:  0 233131\n",
      "X bounds:  0 242661\n",
      "Y bounds:  0 242661\n",
      "X bounds:  0 242796\n",
      "Y bounds:  0 242796\n",
      "X bounds:  0 233131\n",
      "Y bounds:  0 233131\n",
      "X bounds:  0 242799\n",
      "Y bounds:  0 242799\n",
      "X bounds:  0 242796\n",
      "Y bounds:  0 242796\n",
      "X bounds:  0 242799\n",
      "Y bounds:  0 242799\n",
      "X bounds:  0 242796\n",
      "Y bounds:  0 242796\n",
      "X bounds:  0 240596\n",
      "Y bounds:  0 240596\n",
      "X bounds:  0 242435\n",
      "Y bounds:  0 242435\n",
      "X bounds:  0 243317\n",
      "Y bounds:  0 243317\n",
      "X bounds:  0 240596\n",
      "Y bounds:  0 240596\n",
      "X bounds:  0 242435\n",
      "Y bounds:  0 242435\n",
      "X bounds:  0 243317\n",
      "Y bounds:  0 243317\n",
      "X bounds:  0 240239\n",
      "Y bounds:  0 240239\n",
      "X bounds:  0 242799\n",
      "Y bounds:  0 242799\n",
      "X bounds:  0 242435\n",
      "Y bounds:  0 242435\n",
      "X bounds:  0 240239\n",
      "Y bounds:  0 240239\n",
      "X bounds:  0 242799\n",
      "Y bounds:  0 242799\n",
      "X bounds:  0 242435\n",
      "Y bounds:  0 242435\n",
      "X bounds:  0 242796\n",
      "Y bounds:  0 242796\n",
      "X bounds:  0 242661\n",
      "Y bounds:  0 242661\n",
      "X bounds:  0 242796\n",
      "Y bounds:  0 242796\n",
      "X bounds:  0 242661\n",
      "Y bounds:  0 242661\n",
      "X bounds:  0 237332\n",
      "Y bounds:  0 237332\n",
      "X bounds:  0 241522\n",
      "Y bounds:  0 241522\n",
      "X bounds:  0 237332\n",
      "Y bounds:  0 237332\n",
      "X bounds:  0 241522\n",
      "Y bounds:  0 241522\n",
      "X bounds:  0 242661\n",
      "Y bounds:  0 242661\n",
      "X bounds:  0 238478\n",
      "Y bounds:  0 238478\n",
      "X bounds:  0 242435\n",
      "Y bounds:  0 242435\n",
      "X bounds:  0 242661\n",
      "Y bounds:  0 242661\n",
      "X bounds:  0 238478\n",
      "Y bounds:  0 238478\n",
      "X bounds:  0 242435\n",
      "Y bounds:  0 242435\n",
      "X bounds:  0 240906\n",
      "Y bounds:  0 240906\n",
      "step 0: train loss 12.4391, val loss 12.4390\n",
      "X bounds:  0 240906\n",
      "Y bounds:  0 240906\n",
      "step 0: train loss 12.4391, val loss 12.4390\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/multilingual-backpacks/multilingual-backpacks/train.py\", line 331, in <module>\n",
      "    main()\n",
      "  File \"/content/multilingual-backpacks/multilingual-backpacks/train.py\", line 247, in main\n",
      "    loss.backward()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\", line 625, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\", line 841, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacity of 14.74 GiB of which 2.91 GiB is free. Process 25297 has 11.83 GiB memory in use. Of the allocated memory 7.90 GiB is allocated by PyTorch, and 3.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Traceback (most recent call last):\n",
      "  File \"/content/multilingual-backpacks/multilingual-backpacks/train.py\", line 331, in <module>\n",
      "    main()\n",
      "  File \"/content/multilingual-backpacks/multilingual-backpacks/train.py\", line 247, in main\n",
      "    loss.backward()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\", line 625, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\", line 841, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.82 GiB. GPU 0 has a total capacity of 14.74 GiB of which 2.91 GiB is free. Process 25297 has 11.83 GiB memory in use. Of the allocated memory 7.90 GiB is allocated by PyTorch, and 3.80 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    }
   ],
   "source": [
    "# Train using the train.py script with reduced batch size for T4 GPU\n",
    "# The model is ~60M params (larger than expected due to vocab size)\n",
    "# Using smaller batch size to fit in T4's 15GB memory\n",
    "!python train.py \\\n",
    "    --config train_europarl_tiny \\\n",
    "    --out_dir out/tiny \\\n",
    "    --data_dir europarl \\\n",
    "    --device cuda \\\n",
    "    --dtype float16 \\\n",
    "    --model_type backpack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17faa554",
   "metadata": {},
   "source": [
    "**Training will take ~15-20 minutes on T4**\n",
    "\n",
    "Watch for:\n",
    "- Initial loss: ~12.4\n",
    "- Loss should decrease to ~3-5 by iteration 1000\n",
    "- GPU memory usage should stay under 14GB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6328ef30",
   "metadata": {},
   "source": [
    "## 5. Check Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614e6ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed: 1 checkpoints\n",
      "Final train loss: 12.4406\n",
      "Final val loss: 12.4405\n",
      "Loss reduction: 0.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Loss curves saved to out/tiny/loss_curves.png\n"
     ]
    }
   ],
   "source": [
    "# Load and display training log\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open('out/tiny/training_log.json', 'r') as f:\n",
    "    log = json.load(f)\n",
    "\n",
    "iterations = log['iterations']\n",
    "train_loss = log['train_loss']\n",
    "val_loss = log['val_loss']\n",
    "\n",
    "print(f\"Training completed: {len(iterations)} checkpoints\")\n",
    "print(f\"Final train loss: {train_loss[-1]:.4f}\")\n",
    "print(f\"Final val loss: {val_loss[-1]:.4f}\")\n",
    "print(f\"Loss reduction: {train_loss[0] - train_loss[-1]:.4f}\")\n",
    "\n",
    "# Plot loss curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(iterations, train_loss, label='Train Loss', alpha=0.7)\n",
    "plt.plot(iterations, val_loss, label='Val Loss', alpha=0.7)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Tiny Backpack Training Loss Curves')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('out/tiny/loss_curves.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Loss curves saved to out/tiny/loss_curves.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756c62be",
   "metadata": {},
   "source": [
    "## 6. Model Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d043872d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'out/tiny/ckpt.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1639217655.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBackpackLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'out/tiny/ckpt.pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBackpackLM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFileLike\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'out/tiny/ckpt.pt'"
     ]
    }
   ],
   "source": [
    "# Load model and check parameters\n",
    "import torch\n",
    "from model import BackpackLM\n",
    "\n",
    "checkpoint = torch.load('out/tiny/ckpt.pt', map_location='cuda')\n",
    "config = checkpoint['config']\n",
    "model = BackpackLM(config)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"Model Configuration:\")\n",
    "print(f\"  Embedding dim: {config.n_embd}\")\n",
    "print(f\"  Num senses: {config.n_senses}\")\n",
    "print(f\"  Layers: {config.n_layer}\")\n",
    "print(f\"  Heads: {config.n_head}\")\n",
    "print(f\"  Vocab size: {config.vocab_size}\")\n",
    "print(f\"\\nTotal parameters: {n_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Model size: {n_params * 4 / 1e6:.2f} MB (float32)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a82170",
   "metadata": {},
   "source": [
    "## 7. Run Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24f1a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run full evaluation suite\n",
    "!python run_full_evaluation.py --out_dir out/tiny --device cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173b0566",
   "metadata": {},
   "source": [
    "## 8. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903c4c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package results for download\n",
    "!tar -czf tiny_model_results.tar.gz out/tiny/\n",
    "\n",
    "from google.colab import files\n",
    "files.download('tiny_model_results.tar.gz')\n",
    "\n",
    "print(\"\\n✓ Results packaged and ready for download\")\n",
    "print(\"\\nContents:\")\n",
    "print(\"  - ckpt.pt: Model checkpoint\")\n",
    "print(\"  - training_log.json: Training metrics\")\n",
    "print(\"  - evaluation_results.json: Evaluation metrics\")\n",
    "print(\"  - loss_curves.png: Training visualization\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
